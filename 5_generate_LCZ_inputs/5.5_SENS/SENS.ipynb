{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numurbl = 10\n",
    "lsmlat = 1 \n",
    "lsmlon = 1\n",
    "numrad = 2\n",
    "nlevurb = 5 # use 5!!!\n",
    "GRIDNAME=['AU-Pre', 'US-Mi1', 'US-Wes']\n",
    "num_city = len(GRIDNAME)\n",
    "data_dir = '/mnt/iusers01/fatpou01/sees01/a16404ys/CESM/bakeup/UrbanPlumber/'\n",
    "path = data_dir + 'input_files/'\n",
    "output_path = data_dir + 'sensitivity_input/'\n",
    "lcz_type = [0,0,0,0,0,100,0,0,0,0]\n",
    "\n",
    "default = {}\n",
    "for i in range(num_city):\n",
    "    folder = GRIDNAME[i] + '/'\n",
    "    filename = 'surfdata_1x1_'+GRIDNAME[i]+'_detailed_simyr2000_c230710.nc'\n",
    "    ds = xr.open_dataset(path + folder+ filename)\n",
    "    default['ds_' + GRIDNAME[i]] = xr.Dataset()\n",
    "    for var_name in ds.variables:\n",
    "        variable = ds[var_name]\n",
    "        if 'numurbl' in variable.dims:\n",
    "            default['ds_' + GRIDNAME[i]][var_name] = variable\n",
    "\n",
    "datasets = {} # output container\n",
    "for i in range(num_city):\n",
    "    folder = GRIDNAME[i] + '/'\n",
    "    filename = 'surfdata_1x1_'+GRIDNAME[i]+'_detailed_simyr2000_c230710.nc'\n",
    "    ds = xr.open_dataset(path + folder+ filename)\n",
    "    datasets['ds_' + GRIDNAME[i]] = xr.Dataset()\n",
    "    for var_name in ds.variables:\n",
    "        variable = ds[var_name]\n",
    "        if 'numurbl' not in variable.dims:\n",
    "            datasets['ds_' + GRIDNAME[i]][var_name] = variable          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "var0 = ['WALL_TO_PLAN_AREA_RATIO', 'WIND_HGT_CANYON', 'T_BUILDING_MIN', 'NLEV_IMPROAD', 'PCT_URBAN']\n",
    "var1 = ['ALB_IMPROAD_DIF','ALB_PERROAD_DIF','ALB_ROOF_DIF',  'ALB_WALL_DIF', \n",
    "        'EM_IMPROAD', 'EM_PERROAD', 'EM_ROOF', 'EM_WALL']\n",
    "var1_1 = ['ALB_IMPROAD_DIR', 'ALB_PERROAD_DIR', 'ALB_ROOF_DIR', 'ALB_WALL_DIR']\n",
    "var2 = ['CANYON_HWR', 'HT_ROOF', 'THICK_ROOF', \n",
    "        'THICK_WALL', 'WTLUNIT_ROOF', 'WTROAD_PERV']   \n",
    "var3 = ['TK_IMPROAD', 'TK_ROOF', 'TK_WALL', \n",
    "        'CV_ROOF', 'CV_WALL', 'CV_IMPROAD']\n",
    "\n",
    "ai_cesm = [0.14, 0.14, 0.14, 0.14, 0.14, 0.14, 0.14, 0.14, 0.14, 0.14]\n",
    "ap_cesm = [0.08, 0.08 , 0.08 , 0.08 , 0.08 , 0.08 , 0.08 , 0.08 , 0.08 , 0.08]\n",
    "ar_cesm = [0.23, 0.28, 0.25, 0.23, 0.23, 0.23, 0.25 , 0.28 , 0.23 , 0.20]\n",
    "aw_cesm = [0.30, 0.25 , 0.25 , 0.30 , 0.30 , 0.30 , 0.35 , 0.30 , 0.30 , 0.25]\n",
    "ca_cesm = [2.50, 1.25 , 1.25 , 0.75 , 0.50 , 0.50 , 0.90 , 0.20 , 0.15 , 0.35]\n",
    "ht_cesm = [37.50 , 17.50 , 6.50 , 37.50 , 17.50 , 6.50 , 3.00 , 6.50 , 6.50 , 10.00]\n",
    "wi_cesm = np.array(ht_cesm)/2\n",
    "wtr_cesm = [0.53 , 0.61 , 0.65 , 0.46 , 0.43 , 0.50 , 0.88 , 0.47 , 0.50 , 0.45]\n",
    "wtp_cesm = [0.10 , 0.20 , 0.33 , 0.50 , 0.43 , 0.43 , 0.60 , 0.25 , 0.82 , 0.60]\n",
    "li_cesm = [0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8 , 0.8] # TK imperoad\n",
    "lr_cesm = [1.70 , 1.70 , 1.09 , 1.25 , 1.70 , 1.09 , 1.09 , 1.07 , 1.09 , 2.00] # TK roof: thermal conductivity\n",
    "lw_cesm = [1.27 , 2.60 , 1.66 , 1.45 , 1.88 , 1.66 , 1.00 , 1.07 , 1.66 , 1.42 ] # TK wall\n",
    "cr_cesm = [1.32 , 1.32 , 1.32 , 1.80 , 1.32 , 1.32 , 2.00 , 2.11 , 1.32 , 2.00] # CV_ROOF\n",
    "cw_cesm = [1.54 , 1.54 , 1.54 , 2.00 , 1.54 , 1.54 , 2.00 , 2.11 , 1.54 , 1.59] # CV_WALL\n",
    "ci_cesm = [1.80 , 1.80 , 1.80 , 1.80 , 1.80 , 1.80 , 1.80 , 1.80 , 1.80 , 1.80] # CV_IMPROAD: volumetric heat capacity\n",
    "nlev = [3,2,2,2,3,2,2,2,2,2] # NLEV_IMPROAD\n",
    "zr_cesm = [0.30 , 0.30 , 0.20 , 0.30 , 0.25 , 0.15 , 0.10 , 0.12 , 0.15 , 0.10] # THICK_ROOF\n",
    "zw_cesm = [0.30 , 0.25 , 0.25 , 0.20 , 0.20 , 0.20 , 0.10 , 0.20 , 0.20 , 0.10] # 'THICK_WALL\n",
    "ei_cesm = [0.91, 0.91, 0.91, 0.91, 0.91, 0.91, 0.88, 0.91, 0.91, 0.91]\n",
    "ep_cesm = [0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95]\n",
    "er_cesm = [0.91, 0.91, 0.91, 0.91, 0.91, 0.91, 0.88, 0.91, 0.91, 0.91] # emissivity\n",
    "ew_cesm = [0.90, 0.90, 0.90, 0.90, 0.90, 0.90, 0.90, 0.90, 0.90, 0.90]\n",
    "tmin = [291, 287, 287, 291, 287, 287, 287, 287, 287, 287] # T_BUILDING_MIN\n",
    "tmin_c = np.array(tmin)- 273.15\n",
    "\n",
    "crr_cesm = [x * 1000000 for x in cr_cesm]\n",
    "cww_cesm = [x * 1000000 for x in cw_cesm]\n",
    "cii_cesm = [x * 1000000 for x in ci_cesm]\n",
    "\n",
    "ucp1_cesm = [ai_cesm, ap_cesm, ar_cesm, aw_cesm, \n",
    "             ei_cesm, ep_cesm, er_cesm, ew_cesm] \n",
    "ucp2_cesm = [ca_cesm, ht_cesm, zr_cesm, zw_cesm, wtr_cesm, wtp_cesm]\n",
    "ucp3_cesm = [li_cesm, lr_cesm, lw_cesm, crr_cesm, cww_cesm, cii_cesm]\n",
    "\n",
    "for i in range(num_city):\n",
    "    for j in var0:\n",
    "        datasets['ds_' + GRIDNAME[i]][j] = (('numurbl', 'lsmlat', 'lsmlon'), \n",
    "                                            np.zeros((numurbl, lsmlat, lsmlon)))  \n",
    "    for j in var2:\n",
    "        datasets['ds_' + GRIDNAME[i]][j] = (('numurbl', 'lsmlat', 'lsmlon'), \n",
    "                                            np.zeros((numurbl, lsmlat, lsmlon))) \n",
    "    for j , varname in enumerate(var1):\n",
    "        if j < 4:\n",
    "            datasets['ds_' + GRIDNAME[i]][varname] = (('numrad', 'numurbl', 'lsmlat', 'lsmlon'), \n",
    "                                                      np.zeros((numrad, numurbl, lsmlat, lsmlon))) \n",
    "        else:\n",
    "            datasets['ds_' + GRIDNAME[i]][varname] = (('numurbl', 'lsmlat', 'lsmlon'), \n",
    "                                                      np.zeros((numurbl, lsmlat, lsmlon)))\n",
    "    for j in var1_1:    \n",
    "        datasets['ds_' + GRIDNAME[i]][j] = (('numrad','numurbl', 'lsmlat', 'lsmlon'), \n",
    "                                            np.zeros((numrad, numurbl, lsmlat, lsmlon)))   \n",
    "    for j in var3:\n",
    "        datasets['ds_' + GRIDNAME[i]][j] = (('nlevurb','numurbl', 'lsmlat', 'lsmlon'), \n",
    "                                            np.zeros((nlevurb, numurbl, lsmlat, lsmlon)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'WALL_TO_PLAN_AREA_RATIO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/yuanenv/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_virtual_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'WALL_TO_PLAN_AREA_RATIO'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/5197197.1.parallel.q/ipykernel_1903/2418002088.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGRIDNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# use the default\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ds_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGRIDNAME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WALL_TO_PLAN_AREA_RATIO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ds_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGRIDNAME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WALL_TO_PLAN_AREA_RATIO'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ds_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGRIDNAME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'NLEV_IMPROAD'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ds_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGRIDNAME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PCT_URBAN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlcz_type\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ds_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGRIDNAME\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T_BUILDING_MIN'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/yuanenv/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1541\u001b[0m         \"\"\"\n\u001b[1;32m   1542\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dict_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_dataarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterable_of_hashable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copy_listed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1548\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mUnsupported key-type \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/yuanenv/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_virtual_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \u001b[0mneeded_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/yuanenv/lib/python3.12/site-packages/xarray/core/dataset.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(variables, key, dim_sizes)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0msplit_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_key\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mref_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0mref_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mref_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'WALL_TO_PLAN_AREA_RATIO'"
     ]
    }
   ],
   "source": [
    "# morphological parameters\n",
    "# CESM LCZ-table export surface data\n",
    "morphological_combinations = list(itertools.product([1.2, 0.8], repeat=len(var2)))\n",
    "\n",
    "for i in range(len(GRIDNAME)):\n",
    "    for m in range(10):\n",
    "        # use the default \n",
    "        datasets['ds_' + GRIDNAME[i]]['WALL_TO_PLAN_AREA_RATIO'][m, :, :] = default['ds_' + GRIDNAME[i]]['WALL_TO_PLAN_AREA_RATIO'][2, :, :]\n",
    "        datasets['ds_' + GRIDNAME[i]]['NLEV_IMPROAD'][m, :, :] = nlev[m]\n",
    "        datasets['ds_' + GRIDNAME[i]]['PCT_URBAN'][m, :, :] = lcz_type[m]\n",
    "        datasets['ds_' + GRIDNAME[i]]['T_BUILDING_MIN'][m, :, :] = tmin[m]\n",
    "        \n",
    "    for j in range(len(var1)):\n",
    "        for m in range(10):\n",
    "            if j < 4:\n",
    "                datasets['ds_' + GRIDNAME[i]][var1[j]][:, m, :, :] = ucp1_cesm[j][m]\n",
    "                datasets['ds_' + GRIDNAME[i]][var1_1[j]][:, m, :, :] = ucp1_cesm[j][m]\n",
    "            else:\n",
    "                datasets['ds_' + GRIDNAME[i]][var1[j]][m, :, :] = ucp1_cesm[j][m]\n",
    "    \n",
    "    for j in range(len(var3)):\n",
    "        for m in range(10):\n",
    "            datasets['ds_' + GRIDNAME[i]][var3[j]][:, m, :, :] = ucp3_cesm[j][m]            \n",
    "            \n",
    "    for label, change_factors in enumerate(morphological_combinations):\n",
    "        modified_datasets = {}\n",
    "        #label = '_'.join(['{}_{}'.format(var2[j],factor) for j, factor in enumerate(change_factors)])\n",
    "        #label = ''.join(['D' if factor == 1.2 else 'X' for factor in change_factors])\n",
    "        \n",
    "        for j, factor in enumerate(change_factors):\n",
    "            for m in range(10):\n",
    "                modified_data = ucp2_cesm[j][m] * factor\n",
    "                datasets['ds_' + GRIDNAME[i]][var2[j]][m, :, :] = modified_data\n",
    "        for m in range(10):\n",
    "            datasets['ds_' + GRIDNAME[i]]['WIND_HGT_CANYON'][m, :, :] = np.array(datasets['ds_' + GRIDNAME[i]][var2[1]][m, :, :])/2\n",
    "        output = output_path + GRIDNAME[i] + '/surfdata_1x1_'+GRIDNAME[i]+'_detailed_simyr2000_c240510_morp_' + str(label) + '.nc'\n",
    "        output_dir = os.path.dirname(output)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        if os.path.exists(output):\n",
    "            os.remove(output)\n",
    "        datasets['ds_' + GRIDNAME[i]].to_netcdf(output)                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# radiative parameters\n",
    "radiative_combinations = list(itertools.product([1.2, 0.8], repeat=8))\n",
    "\n",
    "for i in range(len(GRIDNAME)):\n",
    "    for m in range(10):\n",
    "        datasets['ds_' + GRIDNAME[i]]['WALL_TO_PLAN_AREA_RATIO'][m, :, :] = default['ds_' + GRIDNAME[i]]['WALL_TO_PLAN_AREA_RATIO'][2, :, :]\n",
    "        datasets['ds_' + GRIDNAME[i]]['NLEV_IMPROAD'][m, :, :] = nlev[m]\n",
    "        datasets['ds_' + GRIDNAME[i]]['PCT_URBAN'][m, :, :] = lcz_type[m]\n",
    "        datasets['ds_' + GRIDNAME[i]]['T_BUILDING_MIN'][m, :, :] = tmin[m]\n",
    "        datasets['ds_' + GRIDNAME[i]]['WIND_HGT_CANYON'][m, :, :] = wi_cesm[m]\n",
    "        \n",
    "    for j in range(len(var2)):\n",
    "        for m in range(10):\n",
    "            datasets['ds_' + GRIDNAME[i]][var2[j]][m, :, :] = ucp2_cesm[j][m]\n",
    "              \n",
    "    for j in range(len(var3)):\n",
    "        for m in range(10):\n",
    "            datasets['ds_' + GRIDNAME[i]][var3[j]][:, m, :, :] = ucp3_cesm[j][m]\n",
    "                   \n",
    "    for label, change_factors in enumerate(radiative_combinations): # for albedo\n",
    "        modified_datasets = {}\n",
    "        for j, factor in enumerate(change_factors):\n",
    "            for m in range(10):\n",
    "                if j < 4:\n",
    "                    modified_data = ucp1_cesm[j][m] * factor\n",
    "                    datasets['ds_' + GRIDNAME[i]][var1[j]][:, m, :, :] = modified_data\n",
    "                    datasets['ds_' + GRIDNAME[i]][var1_1[j]][:, m, :, :] = modified_data\n",
    "                else:\n",
    "                    if factor==0.8: \n",
    "                        factor_for_emissivity=factor + 0.18\n",
    "                    elif factor==1.2: \n",
    "                        factor_for_emissivity=factor - 0.18\n",
    "                    modified_data = ucp1_cesm[j][m] * factor_for_emissivity    \n",
    "                    datasets['ds_' + GRIDNAME[i]][var1[j]][m, :, :] = modified_data\n",
    "                \n",
    "        output = output_path + GRIDNAME[i] + '/surfdata_1x1_'+GRIDNAME[i]+'_detailed_simyr2000_c240510_radi_' + str(label) + '.nc'\n",
    "        output_dir = os.path.dirname(output)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "            \n",
    "        if os.path.exists(output):\n",
    "            os.remove(output)\n",
    "        datasets['ds_' + GRIDNAME[i]].to_netcdf(output)                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thermal parameters\n",
    "# CESM LCZ-table export surface data\n",
    "thermal_combinations = list(itertools.product([1.2, 0.8], repeat=len(var3)))\n",
    "for i in range(len(GRIDNAME)):\n",
    "    for m in range(10):\n",
    "        # use the default \n",
    "        datasets['ds_' + GRIDNAME[i]]['WALL_TO_PLAN_AREA_RATIO'][m, :, :] = default['ds_' + GRIDNAME[i]]['WALL_TO_PLAN_AREA_RATIO'][2, :, :]\n",
    "        datasets['ds_' + GRIDNAME[i]]['NLEV_IMPROAD'][m, :, :] = nlev[m]\n",
    "        datasets['ds_' + GRIDNAME[i]]['PCT_URBAN'][m, :, :] = lcz_type[m]\n",
    "        datasets['ds_' + GRIDNAME[i]]['T_BUILDING_MIN'][m, :, :] = tmin[m]\n",
    "        datasets['ds_' + GRIDNAME[i]]['WIND_HGT_CANYON'][m, :, :] = wi_cesm[m]\n",
    "        \n",
    "    for j in range(len(var1)):\n",
    "        for m in range(10):\n",
    "            if j < 4:\n",
    "                datasets['ds_' + GRIDNAME[i]][var1[j]][:, m, :, :] = ucp1_cesm[j][m]\n",
    "                datasets['ds_' + GRIDNAME[i]][var1_1[j]][:, m, :, :] = ucp1_cesm[j][m]\n",
    "            else:\n",
    "                datasets['ds_' + GRIDNAME[i]][var1[j]][m, :, :] = ucp1_cesm[j][m]\n",
    "    \n",
    "    for j in range(len(var2)):\n",
    "        for m in range(10):\n",
    "            datasets['ds_' + GRIDNAME[i]][var2[j]][m, :, :] = ucp2_cesm[j][m]\n",
    "            \n",
    "            \n",
    "    for label, change_factors in enumerate(thermal_combinations):\n",
    "        modified_datasets = {}\n",
    "        for j, factor in enumerate(change_factors):\n",
    "            for m in range(10):\n",
    "                modified_data = ucp3_cesm[j][m] * factor\n",
    "                datasets['ds_' + GRIDNAME[i]][var3[j]][:, m, :, :] = modified_data\n",
    "    \n",
    "        output = output_path + GRIDNAME[i] + '/surfdata_1x1_'+GRIDNAME[i]+'_detailed_simyr2000_c240510_ther_' + str(label) + '.nc'\n",
    "        output_dir = os.path.dirname(output)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        if os.path.exists(output):\n",
    "            os.remove(output)\n",
    "        datasets['ds_' + GRIDNAME[i]].to_netcdf(output)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indoor temperature parameters\n",
    "# CESM LCZ-table export surface data\n",
    "temperature_combinations = list(itertools.product([1.2,1.15,1.1,1.05,0.95,0.9,0.85,0.8], repeat=1))\n",
    "for i in range(len(GRIDNAME)):\n",
    "    for m in range(10):\n",
    "        # use the default \n",
    "        datasets['ds_' + GRIDNAME[i]]['WALL_TO_PLAN_AREA_RATIO'][m, :, :] = default['ds_' + GRIDNAME[i]]['WALL_TO_PLAN_AREA_RATIO'][2, :, :]\n",
    "        datasets['ds_' + GRIDNAME[i]]['NLEV_IMPROAD'][m, :, :] = nlev[m]\n",
    "        datasets['ds_' + GRIDNAME[i]]['PCT_URBAN'][m, :, :] = lcz_type[m]\n",
    "        datasets['ds_' + GRIDNAME[i]]['WIND_HGT_CANYON'][m, :, :] = wi_cesm[m]\n",
    "        \n",
    "    for j in range(len(var1)):\n",
    "        for m in range(10):\n",
    "            if j < 4:\n",
    "                datasets['ds_' + GRIDNAME[i]][var1[j]][:, m, :, :] = ucp1_cesm[j][m]\n",
    "                datasets['ds_' + GRIDNAME[i]][var1_1[j]][:, m, :, :] = ucp1_cesm[j][m]\n",
    "            else:\n",
    "                datasets['ds_' + GRIDNAME[i]][var1[j]][m, :, :] = ucp1_cesm[j][m]\n",
    "                \n",
    "    for j in range(len(var2)):\n",
    "        for m in range(10):\n",
    "            datasets['ds_' + GRIDNAME[i]][var2[j]][m, :, :] = ucp2_cesm[j][m]\n",
    "            \n",
    "            \n",
    "    for j in range(len(var3)):\n",
    "        for m in range(10):\n",
    "            datasets['ds_' + GRIDNAME[i]][var3[j]][:, m, :, :] = ucp3_cesm[j][m]\n",
    "            \n",
    "    for label, change_factors in enumerate(temperature_combinations):\n",
    "        modified_datasets = {}\n",
    "        for j, factor in enumerate(change_factors):\n",
    "            for m in range(10):\n",
    "                modified_data = tmin_c[m] * factor\n",
    "                datasets['ds_' + GRIDNAME[i]]['T_BUILDING_MIN'][m, :, :] = modified_data + 273.15\n",
    "    \n",
    "        output = output_path + GRIDNAME[i] + '/surfdata_1x1_'+GRIDNAME[i]+'_detailed_simyr2000_c240510_temp_' + str(label) + '.nc'\n",
    "        if os.path.exists(output):\n",
    "            os.remove(output)\n",
    "        datasets['ds_' + GRIDNAME[i]].to_netcdf(output)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.08000000000002"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# morphological change index\n",
    "morphological_combinations = list(itertools.product([1.2, 0.8], repeat=len(var2)))\n",
    "data_list_morp = []       \n",
    "            \n",
    "for label, change_factors in enumerate(morphological_combinations):\n",
    "    label_longname = '_'.join(['{}_{}'.format(var2[j],factor) for j, factor in enumerate(change_factors)])\n",
    "    data_list_morp.append({'Index': label, 'label_longname': label_longname, 'Type': 'morp'})\n",
    "df_morp = pd.DataFrame(data_list_morp) \n",
    "\n",
    "radiative_combinations = list(itertools.product([1.2, 0.8], repeat=8))\n",
    "data_list_radi = [] \n",
    "for label, change_factors in enumerate(radiative_combinations): # for albedo\n",
    "    label_longname = '_'.join(['{}_{}'.format(var1[j],factor) for j, factor in enumerate(change_factors)])\n",
    "    data_list_radi.append({'Index': label, 'label_longname': label_longname, 'Type': 'radi'})\n",
    "df_radi = pd.DataFrame(data_list_radi)     \n",
    "\n",
    "thermal_combinations = list(itertools.product([1.2, 0.8], repeat=len(var3)))\n",
    "data_list_ther = [] \n",
    "for label, change_factors in enumerate(thermal_combinations):\n",
    "    label_longname = '_'.join(['{}_{}'.format(var3[j],factor) for j, factor in enumerate(change_factors)])\n",
    "    data_list_ther.append({'Index': label, 'label_longname': label_longname, 'Type': 'ther'})\n",
    "df_ther = pd.DataFrame(data_list_ther) \n",
    "\n",
    "temperature_combinations = list(itertools.product([1.2,1.15,1.1,1.05, 0.95,0.9,0.85,0.8], repeat=1))\n",
    "data_list_temp = [] \n",
    "for label, change_factors in enumerate(temperature_combinations):\n",
    "    label_longname = '_'.join(['{}_{}'.format('T_BUILDING_MIN',factor) for j, factor in enumerate(change_factors)])\n",
    "    data_list_temp.append({'Index': label, 'label_longname': label_longname, 'Type': 'temp'})\n",
    "df_temp = pd.DataFrame(data_list_temp) \n",
    "\n",
    "combined_df = pd.concat([df_morp, df_radi, df_ther, df_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('index_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>label_longname</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CANYON_HWR_1.2_HT_ROOF_1.2_THICK_ROOF_1.2_THIC...</td>\n",
       "      <td>morp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CANYON_HWR_1.2_HT_ROOF_1.2_THICK_ROOF_1.2_THIC...</td>\n",
       "      <td>morp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>CANYON_HWR_1.2_HT_ROOF_1.2_THICK_ROOF_1.2_THIC...</td>\n",
       "      <td>morp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>CANYON_HWR_1.2_HT_ROOF_1.2_THICK_ROOF_1.2_THIC...</td>\n",
       "      <td>morp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>CANYON_HWR_1.2_HT_ROOF_1.2_THICK_ROOF_1.2_THIC...</td>\n",
       "      <td>morp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>3</td>\n",
       "      <td>T_BUILDING_MIN_1.05</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>4</td>\n",
       "      <td>T_BUILDING_MIN_0.95</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>5</td>\n",
       "      <td>T_BUILDING_MIN_0.9</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>6</td>\n",
       "      <td>T_BUILDING_MIN_0.85</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>7</td>\n",
       "      <td>T_BUILDING_MIN_0.8</td>\n",
       "      <td>temp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Index                                     label_longname  Type\n",
       "0        0  CANYON_HWR_1.2_HT_ROOF_1.2_THICK_ROOF_1.2_THIC...  morp\n",
       "1        1  CANYON_HWR_1.2_HT_ROOF_1.2_THICK_ROOF_1.2_THIC...  morp\n",
       "2        2  CANYON_HWR_1.2_HT_ROOF_1.2_THICK_ROOF_1.2_THIC...  morp\n",
       "3        3  CANYON_HWR_1.2_HT_ROOF_1.2_THICK_ROOF_1.2_THIC...  morp\n",
       "4        4  CANYON_HWR_1.2_HT_ROOF_1.2_THICK_ROOF_1.2_THIC...  morp\n",
       "..     ...                                                ...   ...\n",
       "387      3                                T_BUILDING_MIN_1.05  temp\n",
       "388      4                                T_BUILDING_MIN_0.95  temp\n",
       "389      5                                 T_BUILDING_MIN_0.9  temp\n",
       "390      6                                T_BUILDING_MIN_0.85  temp\n",
       "391      7                                 T_BUILDING_MIN_0.8  temp\n",
       "\n",
       "[392 rows x 3 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (yuanenv)",
   "language": "python",
   "name": "yuanenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
