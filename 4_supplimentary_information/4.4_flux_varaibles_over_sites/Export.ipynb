{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal variations\n",
    "- This script is used to export temporal variations for each site;\n",
    "- Simulations: CNTL, WRF_LCZ, LI_LCZ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cftime\n",
    "import string\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/mnt/iusers01/fatpou01/sees01/a16404ys/scratch/'\n",
    "archive = '/Projects/archive/0project2/'\n",
    "psites = [\"AU-Preston\",\"AU-SurreyHills\",\"CA-Sunset\",\"FI-Kumpula\",\"FI-Torni\",\n",
    "          \"FR-Capitole\",\"GR-HECKOR\",\"JP-Yoyogi\",\"KR-Jungnang\",\"KR-Ochang\",\n",
    "          \"MX-Escandon\",\"NL-Amsterdam\",\"PL-Lipowa\",\"PL-Narutowicza\",\"SG-TelokKurau06\",\n",
    "          \"UK-KingsCollege\",\"UK-Swindon\",\"US-Baltimore\",\"US-Minneapolis1\",\"US-Minneapolis2\",\n",
    "          \"US-WestPhoenix\"]\n",
    "msites = [\"AU-Pre\",\"AU-Sur\",\"CA-Sun\",\"FI-Kum\",\"FI-Tor\",\n",
    "          \"FR-Cap\",\"GR-HEC\",\"JP-Yoy\",\"KR-Jun\",\"KR-Och\",\n",
    "          \"MX-Esc\",\"NL-Ams\",\"PL-Lip\",\"PL-Nar\",\"SG-Tel\",\n",
    "          \"UK-Kin\",\"UK-Swi\",\"US-Bal\",\"US-Mi1\",\"US-Mi2\",\n",
    "          \"US-Wes\"]\n",
    "START = ['1993', '1994', '2002', '2000', '2000',\n",
    "        '1994', '2009', '2006', '2007', '2005', \n",
    "        '2001', '2009', '1998', '1998', '1996', \n",
    "        '2002', '2001', '1992', '1996', '1996', \n",
    "        '2001']\n",
    "END = ['2004', '2004', '2016', '2013', '2013',\n",
    "       '2005', '2020', '2020', '2019', '2017', \n",
    "       '2012', '2020',  '2012', '2012', '2007', \n",
    "       '2014', '2013',  '2007', '2009', '2009',   \n",
    "       '2013']\n",
    "var0 = ['LWdown', 'SWdown']\n",
    "var1 = ['LWdown', 'SWdown','LWup', 'SWup', 'Qh', 'Qle', 'Qtau']\n",
    "var2 = ['FIRE_U', 'FSR', 'FSH_U', 'EFLX_LH_TOT_U', 'TAUX']\n",
    "zone = [10, 10, -8, 2, 2, \n",
    "        1, 2, 9, 9, 9, \n",
    "        -6, 1, 1, 1, 8, \n",
    "        0, 0, -5, -6, -6, \n",
    "        -7]\n",
    "start_date = ['2003-08-12T03:30:00', '2004-02-23T05:00:00', '2012-01-01T00:00:00', '2010-12-31T22:30:00', '2010-12-31T22:30:00',\n",
    "              '2004-02-20T00:30:00', '2019-06-30T22:00:00', '2016-03-31T15:00:00', '2017-01-24T16:00:00', '2015-06-07T15:00:00',\n",
    "              '2011-06-01T17:00:00', '2019-01-01T00:00:00', '2008-01-01T00:00:00', '2008-01-01T00:00:00', '2006-04-30T16:30:00',\n",
    "              '2012-04-04T00:00:00', '2011-05-11T19:00:00', '2002-01-01T05:00:00', '2006-06-01T18:00:00', '2006-06-01T18:00:00',\n",
    "              '2011-12-16T18:30:00']\n",
    "\n",
    "end_date = ['2004-11-28T11:30:00', '2004-07-19T22:00:00', '2016-12-31T22:00:00', '2013-12-31T20:30:00', '2013-12-31T20:30:00',\n",
    "            '2005-02-28T22:30:00', '2020-06-30T20:00:00', '2020-03-31T11:00:00', '2019-04-29T05:00:00', '2017-07-26T00:00:00',\n",
    "            '2012-09-13T12:30:00', '2020-10-13T08:30:00', '2012-12-31T20:00:00', '2012-12-31T20:00:00', '2007-03-31T14:30:00',\n",
    "            '2013-12-31T21:00:00', '2013-04-25T08:00:00', '2007-01-01T01:00:00', '2009-05-29T11:30:00', '2008-01-01T00:00:00',\n",
    "            '2013-01-01T05:00:00']\n",
    "\n",
    "mid_date = [['2004-01-01 00:00:00', '2004-06-01 00:00:00'], ['2004-06-01 00:00:00', '2004-09-01 00:00:00'], ['2014-01-01 00:00:00'], ['2012-01-01 00:00:00', '2013-01-01 00:00:00'], ['2012-01-01 00:00:00', '2013-01-01 00:00:00'],\n",
    "            ['2004-06-01T00:00:00', '2004-12-01T00:00:00'], ['2020-01-01T00:00:00'], ['2018-01-01T00:00:00'], ['2018-01-01T00:00:00'], ['2016-01-01T00:00:00', '2017-01-01T00:00:00'],\n",
    "            ['2012-01-01T00:00:00'], ['2020-01-01T00:00:00'], ['2010-01-01T00:00:00'], ['2010-01-01T00:00:00'], ['2006-09-01T00:00:00', '2007-01-01T00:00:00'],\n",
    "            ['2013-01-01T00:00:00'], ['2012-01-01T00:00:00', '2012-09-01T00:00:00'], ['2004-01-01T00:00:00'], ['2008-01-01T00:00:00'], ['2007-01-01T00:00:00'],\n",
    "            ['2012-06-01T00:00:00']]\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(np.mean((y_true - y_pred) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sitesequence in range(len(psites)):\n",
    "#for sitesequence in [0]:\n",
    "    GRIDNAME = psites[sitesequence]\n",
    "    GRIDNAME_single = msites[sitesequence]\n",
    "    START_year = START[sitesequence]\n",
    "    time_zone = zone[sitesequence] \n",
    "    start_time = start_date[sitesequence]\n",
    "    end_time = end_date[sitesequence]\n",
    "    mid_time = mid_date[sitesequence]\n",
    "    \n",
    "    datm = path + 'UrbanPlumber/datm_files/'+ GRIDNAME_single + '/CLM1PT_data/CTSM_DATM_' + GRIDNAME_single + '_' + START[sitesequence] + '-' + END[sitesequence] + '.nc'\n",
    "    ds_datm = xr.open_dataset(datm)\n",
    "    \n",
    "    observation = path + 'UrbanPlumber/Urban-PLUMBER_FullCollection_v1/' + GRIDNAME + '/timeseries/'+ GRIDNAME + '_clean_observations_v1.nc'\n",
    "    ds_ob = xr.open_dataset(observation)\n",
    "    \n",
    "    #keith = '/mnt/iusers01/fatpou01/sees01/a16404ys/scratch/UrbanPlumber/model_output/CLMU5_AU-Preston_detailed_v3.nc'\n",
    "    keith = path + archive + '0sp/'+ GRIDNAME_single + '_def/lnd/hist/' + GRIDNAME_single + '_def.clm2.h0.' + START_year +'-01-01-00000.nc'\n",
    "    ds_ko = xr.open_dataset(keith)\n",
    "    \n",
    "    wrf = path + archive + '0sp/'+ GRIDNAME_single + '_wrf_all_new/lnd/hist/' + GRIDNAME_single + '_wrf_all_new.clm2.h0.' + START_year +'-01-01-00000.nc'\n",
    "    ds_wrf = xr.open_dataset(wrf)\n",
    "\n",
    "    li = path + archive + '0sp/' + GRIDNAME_single + '_li_all/lnd/hist/' + GRIDNAME_single + '_li_all.clm2.h0.' + START_year +'-01-01-00000.nc'\n",
    "    ds_li = xr.open_dataset(li)\n",
    "    \n",
    "    cesm = path + archive + '0sp/' + GRIDNAME_single + '_cesmlcz/lnd/hist/' + GRIDNAME_single + '_cesmlcz.clm2.h0.' + START_year +'-01-01-00000.nc'\n",
    "    ds_cesm = xr.open_dataset(cesm)\n",
    "    \n",
    "    ds_wrf['time']=ds_wrf['time'].dt.round('min')\n",
    "    ds_wrf['time']=ds_wrf['time'].dt.ceil('min')\n",
    "    ds_li['time']=ds_li['time'].dt.round('min')\n",
    "    ds_li['time']=ds_li['time'].dt.ceil('min')\n",
    "    ds_cesm['time']=ds_cesm['time'].dt.round('min')\n",
    "    ds_cesm['time']=ds_cesm['time'].dt.ceil('min')\n",
    "    ds_ko['time']=ds_ko['time'].dt.round('min')\n",
    "    ds_ko['time']=ds_ko['time'].dt.ceil('min')\n",
    "    \n",
    "    sliced_ds_datm = ds_datm.sel(time=slice(start_time, end_time))[var0]\n",
    "    df_datm = sliced_ds_datm.to_dataframe().reset_index()\n",
    "    \n",
    "    #sliced_ds_ko = ds_ko.sel(time=slice(start_time, end_time))[var1]\n",
    "    sliced_ds_ko = ds_ko.sel(time=slice(start_time, end_time))[var2]\n",
    "    df_ko = sliced_ds_ko.to_dataframe().reset_index()\n",
    "    df_ko.drop(columns=['lndgrid'], inplace=True)\n",
    "    #df_ko = df_ko.rename(columns={'LWup': 'LWup_def', 'SWup': 'SWup_def','Qh': 'Qh_def', 'Qle': 'Qle_def', 'Qtau': 'Qtau_def'})\n",
    "    df_ko = df_ko.rename(columns={'FIRE_U': 'LWup_def', 'FSR': 'SWup_def','FSH_U': 'Qh_def', 'EFLX_LH_TOT_U': 'Qle_def', 'TAUX': 'Qtau_def'})\n",
    "    df_ko['Qtau_def'] = - df_ko['Qtau_def']\n",
    "    df_ko['Rn_def'] = df_datm['LWdown'] + df_datm['SWdown'] - df_ko['SWup_def'] - df_ko['LWup_def']\n",
    "    \n",
    "    sliced_ds_wrf = ds_wrf.sel(time=slice(start_time, end_time))[var2]\n",
    "    df_wrf = sliced_ds_wrf.to_dataframe().reset_index()\n",
    "    df_wrf.drop(columns=['lndgrid'], inplace=True)\n",
    "    df_wrf = df_wrf.rename(columns={'FIRE_U': 'LWup_wrflcz', 'FSR': 'SWup_wrflcz','FSH_U': 'Qh_wrflcz', 'EFLX_LH_TOT_U': 'Qle_wrflcz', 'TAUX': 'Qtau_wrflcz'})\n",
    "    df_wrf['Qtau_wrflcz'] = - df_wrf['Qtau_wrflcz']\n",
    "    df_wrf['Rn_wrflcz'] = df_datm['LWdown'] + df_datm['SWdown'] - df_wrf['SWup_wrflcz'] - df_wrf['LWup_wrflcz']\n",
    "    \n",
    "    sliced_ds_li = ds_li.sel(time=slice(start_time, end_time))[var2]\n",
    "    df_li = sliced_ds_li.to_dataframe().reset_index()\n",
    "    df_li.drop(columns=['lndgrid'], inplace=True)\n",
    "    df_li = df_li.rename(columns={'FIRE_U': 'LWup_lilcz', 'FSR': 'SWup_lilcz','FSH_U': 'Qh_lilcz', 'EFLX_LH_TOT_U': 'Qle_lilcz', 'TAUX': 'Qtau_lilcz'})\n",
    "    df_li['Qtau_lilcz'] = - df_li['Qtau_lilcz']\n",
    "    df_li['Rn_lilcz'] = df_datm['LWdown'] + df_datm['SWdown'] - df_li['SWup_lilcz'] - df_li['LWup_lilcz']\n",
    "    \n",
    "    sliced_ds_cesm = ds_cesm.sel(time=slice(start_time, end_time))[var2]\n",
    "    df_cesm = sliced_ds_cesm.to_dataframe().reset_index()\n",
    "    df_cesm.drop(columns=['lndgrid'], inplace=True)\n",
    "    df_cesm = df_cesm.rename(columns={'FIRE_U': 'LWup_cesmlcz', 'FSR': 'SWup_cesmlcz','FSH_U': 'Qh_cesmlcz', 'EFLX_LH_TOT_U': 'Qle_cesmlcz', 'TAUX': 'Qtau_cesmlcz'})\n",
    "    df_cesm['Qtau_cesmlcz'] = - df_cesm['Qtau_cesmlcz']\n",
    "    df_cesm['Rn_cesmlcz'] = df_datm['LWdown'] + df_datm['SWdown'] - df_cesm['SWup_cesmlcz'] - df_cesm['LWup_cesmlcz']\n",
    "    \n",
    "    if sitesequence in [3, 4, 7, 8, 9, 12, 13, 14]:\n",
    "        sliced_ds_ob = ds_ob.sel(time=slice(start_time, end_time))[['LWdown', 'SWdown','LWup', 'SWup', 'Qh', 'Qle']]\n",
    "        df_ob = sliced_ds_ob.to_dataframe().reset_index()\n",
    "        df_ob = df_ob.rename(columns={'LWdown': 'LWdown_obs', \n",
    "                                      'SWdown': 'SWdown_obs',\n",
    "                                      'LWup': 'LWup_obs', \n",
    "                                      'SWup': 'SWup_obs',\n",
    "                                      'Qh': 'Qh_obs', \n",
    "                                      'Qle': 'Qle_obs'})\n",
    "        df_ob['Qtau_obs'] = np.nan\n",
    "        \n",
    "    else: \n",
    "        sliced_ds_ob = ds_ob.sel(time=slice(start_time, end_time))[var1]\n",
    "        df_ob = sliced_ds_ob.to_dataframe().reset_index()\n",
    "        df_ob = df_ob.rename(columns={'LWdown': 'LWdown_obs', \n",
    "                                      'SWdown': 'SWdown_obs',\n",
    "                                      'LWup': 'LWup_obs', \n",
    "                                      'SWup': 'SWup_obs',\n",
    "                                      'Qh': 'Qh_obs', \n",
    "                                      'Qle': 'Qle_obs', \n",
    "                                      'Qtau': 'Qtau_obs'})\n",
    "    df_ob['Rn_obs'] = df_ob['LWdown_obs'] + df_ob['SWdown_obs']-df_ob['SWup_obs']-df_ob['LWup_obs']\n",
    "    df = pd.merge(df_ob, df_ko, on='time').merge(df_wrf, on='time').merge(df_li, on='time').merge(df_cesm, on='time')\n",
    "    df.loc[df['LWup_obs'].isna(), ['LWup_wrflcz', 'LWup_lilcz','LWup_def','LWup_cesmlcz',\n",
    "                                  'Rn_obs', 'Rn_wrflcz', 'Rn_lilcz', 'Rn_def', 'Rn_cesmlcz']] = np.nan\n",
    "    df.loc[df['SWup_obs'].isna(), ['SWup_wrflcz', 'SWup_lilcz', 'SWup_def', 'SWup_cesmlcz',\n",
    "                                  'Rn_obs', 'Rn_wrflcz', 'Rn_lilcz', 'Rn_def', 'Rn_cesmlcz']] = np.nan\n",
    "    df.loc[df['Qle_obs'].isna(), ['Qle_wrflcz', 'Qle_lilcz','Qle_def', 'Qle_cesmlcz']] = np.nan\n",
    "    df.loc[df['Qh_obs'].isna(), ['Qh_wrflcz', 'Qh_lilcz','Qh_def', 'Qh_cesmlcz']] = np.nan\n",
    "    df.loc[df['Qtau_obs'].isna(), ['Qtau_wrflcz', 'Qtau_lilcz','Qtau_def', 'Qtau_cesmlcz']] = np.nan\n",
    "\n",
    "    df['hour']=(df.time.dt.hour + time_zone) % 24\n",
    "    df['minute']=df.time.dt.minute\n",
    "    df['diurnal']=df['hour'].astype(str).str.zfill(2) + ':' + df['minute'].astype(str).str.zfill(2)\n",
    "    output_dir = path + 'output_analysis/project2/sp/temperal_variation/output/'\n",
    "    df.to_csv(output_dir + GRIDNAME + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (yuanenv)",
   "language": "python",
   "name": "yuanenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
